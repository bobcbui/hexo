{"meta":{"title":"子非鱼","subtitle":"不轻信别人的结论，实践才是检验真理的唯一标准","description":"","author":"haung ding","url":"https://huang-ding.github.io/hexo","root":"/hexo/"},"pages":[{"title":"categories","date":"2020-04-26T07:11:28.000Z","updated":"2020-04-26T07:11:45.866Z","comments":false,"path":"categories/index.html","permalink":"https://huang-ding.github.io/hexo/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-04-26T07:10:24.000Z","updated":"2020-04-26T07:11:17.823Z","comments":false,"path":"tags/index.html","permalink":"https://huang-ding.github.io/hexo/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"zookeeper典型应用场景","slug":"distributed-zk-apply","date":"2020-05-08T11:59:13.000Z","updated":"2020-05-10T14:20:59.807Z","comments":true,"path":"2020/05/08/distributed-zk-apply/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/05/08/distributed-zk-apply/","excerpt":"","text":"数据发布订阅(配置中心)何为配置中心：解决系统参数配置，动态该参通知 用zookeeper实现配置中心 znode能存储数据 一个配置项一个znode 一个配置文件一个znode Watch能监听数据变化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * zk 配置中心demo */public class ConfigCenterDemo &#123; //普通配置 public static void put2Zk(String key, String value) &#123; ZkClient client = new ZkClient(\"localhost:2181\"); client.setZkSerializer(new MyZkSerializer()); if (client.exists(key)) &#123; client.writeData(key, value); &#125; else &#123; client.createPersistent(key, value); &#125; client.close(); &#125; //文件配置 public static void put2ZKFile(String key, File file) throws IOException &#123; FileInputStream fileInputStream = new FileInputStream(file); byte[] data = new byte[(int) file.length()]; fileInputStream.read(data); fileInputStream.close(); ZkClient client = new ZkClient(\"localhost:2181\"); //选择对应的序列号实现 client.setZkSerializer(new BytesPushThroughSerializer()); if (client.exists(key)) &#123; client.writeData(key, data); &#125; else &#123; client.createPersistent(key, data); &#125; client.close(); &#125; public static void get(String key) &#123; ZkClient client = new ZkClient(\"localhost:2181\"); client.setZkSerializer(new MyZkSerializer()); String value = client.readData(key); System.out.println(\"从zk读到配置\" + key + \"的值为：\" + value); //监听配置变化 client.subscribeDataChanges(key, new IZkDataListener() &#123; @Override public void handleDataChange(String dataPath, Object data) throws Exception &#123; System.out.println(\"配置更新：\" + data); &#125; @Override public void handleDataDeleted(String dataPath) throws Exception &#123; System.out.println(\"配置已删除\"); &#125; &#125;); // 这里只是为演示实时获取到配置值更新而加的等待。实际项目应用中根据具体场景写（可用阻塞方式） try &#123; Thread.sleep(5 * 60 * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; client.close(); &#125; public static void main(String[] args) throws IOException &#123;// ConfigCenterDemo.put2Zk(\"/hd\",\"666\");// ConfigCenterDemo.get(\"/hd\"); File f = new File(ConfigCenterDemo.class.getResource(\"/application.yml\").getFile()); ConfigCenterDemo.put2ZKFile(\"/hdFile\",f); ConfigCenterDemo.get(\"/hdFile\"); &#125;&#125; 命名服务何为命名服务：服务之间通过服务名称可以动态获取到服务调用地址 1234567891011121314151617181920212223242526public class NamespacesZk &#123; public static void registered(String serverName, String serverAddress) &#123; ConfigCenterDemo.put2Zk(serverName, serverAddress); &#125; public static void main(String[] args) &#123; //服务B注册 registered(\"/serverB\", \"http://www.baidu.com\"); //服务A监听 ZkClient client = new ZkClient(\"localhost:2181\"); client.setZkSerializer(new MyZkSerializer()); String addressB = client.readData(\"/serverB\"); client.subscribeDataChanges(\"/serverB\", new IZkDataListener() &#123; @Override public void handleDataChange(String dataPath, Object data) throws Exception &#123; System.out.println(\"serverB服务的地址变化\"); &#125; @Override public void handleDataDeleted(String dataPath) throws Exception &#123; &#125; &#125;); &#125;&#125; Master选举何为Master选举：分布式服务主从结构一主多从，当主节点不可用时，自动选取出新的子节点 zookeeper实现Master选举 使用临时节点，争取创建主节点 使用临时节点防止主节点挂掉无法通知其他节点 创建servers节点，创建临时/临时顺序子节点，管理当前可用节点信息 使用临时顺序节点，可以使用最小节点当做主节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135/** * zk Master 选举 demo */public class MasterElectionDemo &#123; static class Server &#123; //集群名称 节点名称 节点地址 private String clusterName, nodeName, nodeAddress; private String masterInfo; //当前节点目录 数据 private final String path, value; //可用节点信息 private String serversPath; private List&lt;String&gt; servers; public Server(String clusterName, String nodeName, String nodeAddress) &#123; this.clusterName = clusterName; this.nodeName = nodeName; this.nodeAddress = nodeAddress; this.path = \"/\" + this.clusterName + \"Master\"; this.serversPath = \"/\" + this.clusterName + \"servers\"; this.value = \"nodeName:\" + nodeAddress + \" nodeAddress:\" + nodeAddress; ZkClient client = new ZkClient(\"localhost:2181\"); client.setZkSerializer(new MyZkSerializer()); new Thread(new Runnable() &#123; @Override public void run() &#123; //节点注册 electionMaster(client); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; //当前存活节点数据获取 electionServers(client); &#125; &#125;).start(); &#125; private void createServers(ZkClient client) &#123; if (!client.exists(serversPath)) &#123; client.createPersistent(serversPath); &#125; try &#123; client.createEphemeral(serversPath + \"/\" + nodeName, nodeAddress); &#125; catch (ZkNodeExistsException e) &#123; client.writeData(serversPath + \"/\" + nodeName, nodeAddress); &#125; &#125; private void electionServers(ZkClient client) &#123; //阻塞等待 CountDownLatch latch = new CountDownLatch(1); IZkChildListener iZkChildListener = new IZkChildListener() &#123; @Override public void handleChildChange(String parentPath, List&lt;String&gt; currentChilds) throws Exception &#123; List&lt;String&gt; children = client.getChildren(parentPath); servers = new ArrayList&lt;&gt;(); for (String child : children) &#123; System.out.println(\"子节点消息：\" + child); servers.add(client.readData(parentPath + \"/\" + child)); &#125; System.out.println(\"存活子节点：\" + servers); latch.countDown(); &#125; &#125;; client.subscribeChildChanges(serversPath, iZkChildListener); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; electionServers(client); &#125; private void electionMaster(ZkClient client) &#123; //创建当前存活节点信息 createServers(client); try &#123; //创建Master节点 client.createEphemeral(path, value); System.out.println(value + \"创建节点成功，成为Master\"); &#125; catch (ZkNodeExistsException e) &#123; &#125; masterInfo = client.readData(path); System.out.println(\"当前主节点为:\" + masterInfo); //阻塞等待 CountDownLatch latch = new CountDownLatch(1); IZkDataListener iZkDataListener = new IZkDataListener() &#123; @Override public void handleDataChange(String dataPath, Object data) throws Exception &#123; &#125; @Override public void handleDataDeleted(String dataPath) throws Exception &#123; //节点删除 进行主节点选举 唤醒 latch.countDown(); &#125; &#125;; //监听主节点 client.subscribeDataChanges(path, iZkDataListener); //阻塞 等待唤醒 if (client.exists(path)) &#123; try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //取消监听 client.unsubscribeDataChanges(path, iZkDataListener); //递归调用 进行下一次选举 electionMaster(client); &#125; &#125; public static void main(String[] args) &#123; // 测试时，依次开启多个Server实例java进程，然后停止获取的master的节点，看谁抢到Master// Server s = new Server(\"cluster1\", \"server1\", \"192.168.1.11:8991\"); Server s = new Server(\"cluster1\", \"server2\", \"192.168.1.11:8992\");// Server s = new Server(\"cluster1\", \"server3\", \"192.168.1.11:8993\");// Server s = new Server(\"cluster1\", \"server4\", \"192.168.1.11:8994\"); &#125;&#125; 分布式队列zookeeper实现分布式队列：使用顺序节点，入队(创建顺序节点)，出队(消费者取出所有子节点，移除最小号节点) 无界队列 有界队列 分布式锁，判断是否到达上限，防止超界 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/** * zk 分布式队列 简易demo * * @author huangding * @date 2020/5/10 20:18 */public class ZKQueue &#123; private final String queueName; private final int size; public ZKQueue(String queueName) &#123; this.queueName = queueName; size = Integer.MAX_VALUE; &#125; public ZKQueue(String queueName, int size) &#123; this.queueName = queueName; this.size = size; &#125; public void add(String value) &#123; ZkClient client = new ZkClient(\"localhost:2181\"); client.setZkSerializer(new MyZkSerializer()); try &#123; client.createPersistent(\"/\" + queueName); &#125; catch (ZkNodeExistsException e) &#123; &#125; List&lt;String&gt; children = client.getChildren(\"/\" + this.queueName); int childrenSize = children.size(); //TODO 正式情况需要使用分布式锁 ，有界队列 if (childrenSize &gt;= this.size) &#123; //队列已满 return; &#125; client.createPersistentSequential(\"/\" + queueName + \"/queue\", value); client.close(); System.out.println(\"入队：\" + value); &#125; public String poll() &#123; ZkClient client = new ZkClient(\"localhost:2181\"); client.setZkSerializer(new MyZkSerializer()); //TODO 正常情况消费需要加锁防止重复消费 List&lt;String&gt; children = client.getChildren(\"/\" + this.queueName); if (null == children || children.size() == 0) &#123; return null; &#125; Collections.sort(children); //移除最小节点 String s = children.get(0); String data = client.readData(\"/\" + this.queueName + \"/\" + s); client.delete(\"/\" + this.queueName + \"/\" + s); client.close(); System.out.println(\"出队：\" + data); return data; &#125; public static void main(String[] args) &#123; ZKQueue zkQueue = new ZKQueue(\"hdQueue\"); zkQueue.add(\"1\"); zkQueue.add(\"2\"); zkQueue.add(\"3\"); zkQueue.add(\"4\"); boolean f = true; do &#123; String poll = zkQueue.poll(); if (null == poll) &#123; f = false; &#125; &#125; while (f); &#125;&#125; 分布式锁zookeeper实现分布式锁： 挣抢锁，利用临时节点，原理：节点不可重名+watch;缺点：惊群效应 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143/** * zk 挣抢锁 实现demo 缺点惊群效应 */public class ZKDistributeLock implements Lock &#123; private final String lockPath; private ZkClient client; /** * 重入次数 */ private ThreadLocal&lt;Integer&gt; reentrantCount = new ThreadLocal&lt;&gt;(); public ZKDistributeLock(String lockPath) &#123; this.lockPath = \"/\" + lockPath; ZkClient client = new ZkClient(\"localhost:2181\"); client.setZkSerializer(new MyZkSerializer()); this.client = client; &#125; @Override public void lock() &#123; if (!tryLock()) &#123; //阻塞 waitForLock(); //再次尝试 lock(); &#125; &#125; private void waitForLock() &#123; CountDownLatch latch = new CountDownLatch(1); IZkDataListener listener = new IZkDataListener() &#123; @Override public void handleDataChange(String dataPath, Object data) throws Exception &#123; &#125; @Override public void handleDataDeleted(String dataPath) throws Exception &#123; //锁节点删除，开始抢锁 System.out.println(\"收到节点删除\"); latch.countDown(); &#125; &#125;; //watch监听 client.subscribeDataChanges(lockPath, listener); //阻塞 if (client.exists(lockPath)) &#123; try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // 取消监听事件，进行抢锁 client.unsubscribeDataChanges(lockPath, listener); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; &#125; @Override public boolean tryLock() &#123; //可重入判断 if (reentrantCount.get() != null) &#123; Integer count = reentrantCount.get(); if (count &gt; 0) &#123; reentrantCount.set(++count); return true; &#125; &#125; try &#123; //创建锁的临时节点 client.createEphemeral(lockPath); reentrantCount.set(1); return true; &#125; catch (ZkNodeExistsException e) &#123; return false; &#125; &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return false; &#125; @Override public void unlock() &#123; //判断重入锁释放 if (reentrantCount != null) &#123; Integer count = reentrantCount.get(); if (count &gt; 1) &#123; reentrantCount.set(--count); &#125; else &#123; reentrantCount.set(null); &#125; &#125; //删除节点，释放锁 client.delete(lockPath); &#125; @Override public Condition newCondition() &#123; return null; &#125; public static void main(String[] args) &#123; int cbCount = 50; //模拟高并发 CyclicBarrier cb = new CyclicBarrier(cbCount); for (int i = 0; i &lt; cbCount; i++) &#123; new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \"线程已准备\"); try &#123; cb.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; ZKDistributeLock lock = new ZKDistributeLock(\"testLock\"); try &#123; lock.lock(); System.out.println(Thread.currentThread().getName() + \"或得锁\"); &#125; finally &#123; lock.unlock(); &#125; &#125;).start(); &#125; &#125;&#125; 取号，利用临时顺序节点来实现分布式锁；，获取锁：取排队号（创建自己的临时顺序节点），然后判断自己是否是最小号，如是，则获得锁；不是，则注册前一节点的watcher,阻塞等待，释放锁：删除自己创建的临时顺序节点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178/** * zk 利用临时顺序节点来实现分布式锁 实现demo */public class ZKDistributeImproveLock implements Lock &#123; /* * 利用临时顺序节点来实现分布式锁 * 获取锁：取排队号（创建自己的临时顺序节点），然后判断自己是否是最小号，如是，则获得锁；不是，则注册前一节点的watcher,阻塞等待 * 释放锁：删除自己创建的临时顺序节点 */ private String lockPath; private ZkClient client; private ThreadLocal&lt;String&gt; currentPath = new ThreadLocal&lt;&gt;(); private ThreadLocal&lt;String&gt; beforePath = new ThreadLocal&lt;&gt;(); // 锁重入计数 private ThreadLocal&lt;Integer&gt; reentrantCount = new ThreadLocal&lt;&gt;(); public ZKDistributeImproveLock(String lockPath) &#123; super(); this.lockPath = lockPath; client = new ZkClient(\"localhost:2181\"); client.setZkSerializer(new MyZkSerializer()); if (!this.client.exists(lockPath)) &#123; try &#123; this.client.createPersistent(lockPath); &#125; catch (ZkNodeExistsException e) &#123; &#125; &#125; &#125; @Override public boolean tryLock() &#123; if (this.reentrantCount.get() != null) &#123; int count = this.reentrantCount.get(); if (count &gt; 0) &#123; this.reentrantCount.set(++count); return true; &#125; &#125; if (this.currentPath.get() == null) &#123; currentPath.set(this.client.createEphemeralSequential(lockPath + \"/\", \"aaa\")); &#125; // 获得所有的子 List&lt;String&gt; children = this.client.getChildren(lockPath); // 排序list Collections.sort(children); // 判断当前节点是否是最小的 if (currentPath.get().equals(lockPath + \"/\" + children.get(0))) &#123; this.reentrantCount.set(1); return true; &#125; else &#123; // 取到前一个 // 得到字节的索引号 int curIndex = children.indexOf(currentPath.get().substring(lockPath.length() + 1)); beforePath.set(lockPath + \"/\" + children.get(curIndex - 1)); &#125; return false; &#125; @Override public void lock() &#123; if (!tryLock()) &#123; // 阻塞等待 waitForLock(); // 再次尝试加锁 lock(); &#125; &#125; private void waitForLock() &#123; CountDownLatch cdl = new CountDownLatch(1); // 注册watcher IZkDataListener listener = new IZkDataListener() &#123; @Override public void handleDataDeleted(String dataPath) throws Exception &#123; System.out.println(\"-----监听到节点被删除\"); cdl.countDown(); &#125; @Override public void handleDataChange(String dataPath, Object data) throws Exception &#123; &#125; &#125;; client.subscribeDataChanges(this.beforePath.get(), listener); // 怎么让自己阻塞 if (this.client.exists(this.beforePath.get())) &#123; try &#123; cdl.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // 醒来后，取消watcher client.unsubscribeDataChanges(this.beforePath.get(), listener); &#125; @Override public void unlock() &#123; // 重入的释放锁处理 if (this.reentrantCount.get() != null) &#123; int count = this.reentrantCount.get(); if (count &gt; 1) &#123; this.reentrantCount.set(--count); return; &#125; else &#123; this.reentrantCount.set(null); &#125; &#125; // 删除节点 this.client.delete(this.currentPath.get()); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; // TODO Auto-generated method stub &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; // TODO Auto-generated method stub return false; &#125; @Override public Condition newCondition() &#123; // TODO Auto-generated method stub return null; &#125; public static void main(String[] args) &#123; // 并发数 int currency = 50; // 循环屏障 CyclicBarrier cb = new CyclicBarrier(currency); // 多线程模拟高并发 for (int i = 0; i &lt; currency; i++) &#123; new Thread(new Runnable() &#123; public void run() &#123; System.out.println(Thread.currentThread().getName() + \"---------我准备好---------------\"); // 等待一起出发 try &#123; cb.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; ZKDistributeImproveLock lock = new ZKDistributeImproveLock(\"/distLock111\"); try &#123; lock.lock(); System.out.println(Thread.currentThread().getName() + \" 获得锁！\"); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;).start(); &#125; &#125;&#125;","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://huang-ding.github.io/hexo/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"zk","slug":"zk","permalink":"https://huang-ding.github.io/hexo/tags/zk/"}]},{"title":"zookeeper核心概念","slug":"distributed-zk-core","date":"2020-05-07T11:55:40.000Z","updated":"2020-05-08T13:51:53.100Z","comments":true,"path":"2020/05/07/distributed-zk-core/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/05/07/distributed-zk-core/","excerpt":"","text":"Session会话 一个客户端链接一个会话，由zk分配唯一会话id；列:session id = 0x1001bb1f6720002 客户端以特定的时间间隔发送心跳以保持会话有效；tickTime 超过会话超时时间未收到客户端心跳，则判定客户端挂了；(默认2倍tickTime) minSessionTimeout : (No Java system property) New in 3.3.0: the minimum session timeout in milliseconds that the server will allow the client to negotiate. Defaults to 2 times the tickTime. maxSessionTimeout : (No Java system property) New in 3.3.0: the maximum session timeout in milliseconds that the server will allow the client to negotiate. Defaults to 20 times the tickTime. 会话中的请求按照FIFO(fast in fast on)顺序执行. 数据模型 层次名称空间 类型Unix文件系统，以(/)为根目录 区别：节点可以包含与之关联的数据以及子节点(即是文件也是文件夹) 节点的路径总是表示未规范的，绝对的，斜杠分隔的路径 znode 名称唯一，命名规范 null字符(\\u000)不能作为路劲的一部分 \\u0001-\\u0019和\\u007F-\\u009F不能使用，因为他们不能很好的显示，或者以令人困惑的方式 \\ud800-uf8fff,\\uFFF0-uFFFF不可使用 “.”字符可以用作另一个名称的一部分，但是“.”和”..”不能单独用于指示路劲上的节点，因为ZK不使用相对路径，“/a/b/./c”或“c/b/b/../”无效 “zookeeper”是保留节点名称 节点类型 持久 1create /app1 666 顺序 10位十进制序号 每个父节点一个计算器 计数器是带符号int(4字节)，到2147483647后将溢出为负值 12create -e /app2 666nodeName: app20000000001 临时 和客户端挂钩，当客户端断开时销毁 1create -s /app3 666 临时顺序 1create -s -e /app4 666 节点数据构成 节点数据：存储的协调数据(状态信息，配置信息，位置信息等) 节点元数据(stat结构) 数据量上限：1M 访问控制列表 ACLs are made up of pairs of (scheme:expression, perms)，the pair (ip:19.22.0.0/16, READ) ACL Permissions CREATE: you can create a child node READ: you can get data from a node and list its children. WRITE: you can set data for a node DELETE: you can delete a child node Builtin ACL Schemes world has a single id, anyone, that represents anyone. auth is a special scheme which ignores any provided expression and instead uses the current user, credentials, and scheme. Any expression (whether user like with SASL authentication or user:password like with DIGEST authentication) provided is ignored by the ZooKeeper server when persisting the ACL. However, the expression must still be provided in the ACL because the ACL must match the form scheme:expression:perms. This scheme is provided as a convenience as it is a common use-case for a user to create a znode and then restrict access to that znode to only that user. If there is no authenticated user, setting an ACL with the auth scheme will fail. digest uses a username:password string to generate MD5 hash which is then used as an ACL ID identity. Authentication is done by sending the username:password in clear text. When used in the ACL the expression will be the username:base64 encoded SHA1 password digest. ip uses the client host IP as an ACL ID identity. The ACL expression is of the form addr/bits where the most significant bits of addr are matched against the most significant bits of the client host IP. x509 uses the client X500 Principal as an ACL ID identity. The ACL expression is the exact X500 Principal name of a client. When using the secure port, clients are automatically authenticated and their auth info for the x509 scheme is set. Zookeeper中的时间 Zxid zookeeper中每次更改操作都对应一个唯一的事物id，称为zxid，它是一个全局有序的戳记，如果zxid1小于zxid2，则zxid1发送在zxid2之前 Version number 版本号，对节点的每次更改都会导该改节点的版本号之一增加 *Ticks * 用多服务器Zookeeper时，服务器使用‘’滴答‘’来定义时间的类型，如状态上传，会话超时，对等点之间的链接超时。滴答时间仅提供最小会话超时(滴答2倍)间接公开；如果客户端请求的会话时间小于最小会话超时，服务器将告诉客户端实际上是最小会话超时 RealTime Zookeeper除了在znode 创建和修改时将时间戳放入stat结构之外，其他根本不使用RealTime或时钟时间 watch机制 客户端可以在znodes上设置watch，监听znode变化 设置命令 -w 代表设置watch config [-c] [-w] [-s] get [-s] [-w] path ls [-s] [-w] [-R] path stat [-w] path watch类型 getData() 监听数据变化 getChildren() 监听子节点变化 exists() 是否存在 触发watch事件 Created event: Enabled with a call to exists. Deleted event: Enabled with a call to exists, getData, and getChildren. Changed event: Enabled with a call to exists and getData. Child event: Enabled with a call to getChildren. watch的重要特性 一次性触发：watch触发后即被删除，要持续监控变化，则需要持续的设置watch 有序性：客户端先得到watch通知，后才会看到变好结果 watch注意事项 watch是一次性触发器；如果您获得一个watch事件，并且希望得到关于未来的更改通知，需要设置另一个watch 因为watch是一次性触发器，并且在获取事件和发送获取watch的新请求之前存在时间间隔，所以不能可靠的获取到节点发生的每个更改 一个watch对象只会被特定的通知触发一次。如果一个watch对象同时注册了exists和getData，当节点删除事件对exists和getData都有效，但是只会调用一次 使用zkclient 监听watch事件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class ZkClientWatchDemo &#123; public static void main(String[] args) &#123; // 创建一个zk客户端 ZkClient client = new ZkClient(\"localhost:2181\"); client.setZkSerializer(new MyZkSerializer()); client.subscribeDataChanges(\"/mike/a\", new IZkDataListener() &#123; @Override public void handleDataDeleted(String dataPath) throws Exception &#123; System.out.println(\"----收到节点被删除了-------------\"); &#125; @Override public void handleDataChange(String dataPath, Object data) throws Exception &#123; System.out.println(\"----收到节点数据变化：\" + data + \"-------------\"); &#125; &#125;); try &#123; Thread.sleep(1000 * 60 * 2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;public class MyZkSerializer implements ZkSerializer &#123; String charset = \"UTF-8\"; @Override public Object deserialize(byte[] bytes) throws ZkMarshallingError &#123; try &#123; return new String(bytes, charset); &#125; catch (UnsupportedEncodingException e) &#123; throw new ZkMarshallingError(e); &#125; &#125; @Override public byte[] serialize(Object obj) throws ZkMarshallingError &#123; try &#123; return String.valueOf(obj).getBytes(charset); &#125; catch (UnsupportedEncodingException e) &#123; throw new ZkMarshallingError(e); &#125; &#125;&#125; Zookeeper特性 顺序一致性：保证客户端操作是按照顺序生效的 原子性：更新成功或失败，没有部分结果 单个系统映像：无论链接那个服务器，客户端都将看到相同的内容 可靠性：数据的变更不会丢失，除非被客户覆盖修改，数据变更时先写日志文件，再变更，如果是集群将发送集群变更命令，保证数据写入的可靠性 及时性：保证系统的客户端当时读取到的数据是最新的","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://huang-ding.github.io/hexo/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"zk","slug":"zk","permalink":"https://huang-ding.github.io/hexo/tags/zk/"}]},{"title":"zk入门","slug":"distributed-zk","date":"2020-05-06T11:57:23.000Z","updated":"2020-05-07T12:53:06.586Z","comments":true,"path":"2020/05/06/distributed-zk/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/05/06/distributed-zk/","excerpt":"","text":"什么是ZooKeeper起源：ZooKeeper 最早起源于雅虎研究院的一个研究小组。当时，雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是这些系统往往都存在分布式单点问题。所以，雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人员将精力集中在处理业务逻辑上。 简介：Apache Zookeeper是一种用于分布式应用程序的高性能协调服务，提供一种集中式信息存储服务 特点：数据存在内存中，类型文件系统的树形结构（文件和目录），高吞吐和低延迟，集群高可用 作用：基于zookeeper可以实现分布式统一配置中心，服务注册发现，分布式锁等 官网：https://zookeeper.apache.org/ 何为分布式协调服务 单机系统因处理能力上限，可用性，可靠性的考虑，变为分布式系统 原来的单机进程中完成的一件事的多个步骤，变为在多个计算机中完成，这时候就需要协调各个计算机节点做事情的顺序；原来在单系统中资源通过竞争通过锁进行同步控制；现在变成了多个计算机的进程之间的资源竞争，也需要资源协调。 我们可以把每个分布式系统中需要协调的协调管理的公共基础部分抽取出来作为一个基础公共服务，供大家使用，这就是分布式协调 zookeeper的应用案例 Hbase：使用Zookeeper进行Master选举，服务间协调 Solr：使用Zookeeper进行集群管理，Leader选举，配置中心 dubbo：服务注册发现 Mycat：集群管理，配置管理 Sharding-sphere：集群管理，配置管理 。。。。 zookeeper同类产品 consul，etcd，Doozer，等其中etcd和Doozer实现原理，存储方式和zk类似 单机版安装 官网下载对应版本压缩包 3.6.1版本安装包 解压后的conf目录，添加配置文件zoo.cfg（默认文件名，可以不使用此文件名，启动时指定便可） 启动服务端 bin/zkServer.sh start 测试，客户端链接：/bin/zkCli.sh -server 127.0.0.1:2181 123456789//单机版主要配置# The number of milliseconds of each tick 心跳时间tickTime=2000# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes. 数据存放目录dataDir=F:/zk/data# the port at which the clients will connect 客户端链接端口clientPort=2181 客户端操作命令 命令 命令参数 功能描述 addauth addauth scheme auth 创建 &amp;&amp; 验证用户 close - 关闭客户端 config config [-c] [-w] [-s] - connect connect host:port 客户端链接 create create [-s] [-e] [-c] [-t ttl] path [data] [acl] 创建节点 delete delete [-v version] path 删除节点 deleteall deleteall path 删除全部节点 rmr rmr path 递归删除节点 delquota delquota [-n |-b] path 用于删除已经创建的quota配额： get get [-s] [-w] path 获取节点值 getAcl getAcl [-s] path 获取节点信息 getAllChildrenNumber getAllChildrenNumber path 获取所有子节点数 getEphemeral getEphemerals path 获取临时节点 history - - listquota listquota path - ls ls [-s] [-w] [-R] path 获取节点信息 printwatches printwatches on off quit - 退出终端 reconfig [-s] [-v version] [[-file path] [-members serverID=host:port1:port2;port3[,…]*]] - redo redo cmdno - removewatches removewatches path [-c|-d|-a] [-1] - set set [-s] [-v version] path data 设置节点值 setAcl setAcl [-s] [-v version] [-R] path acl 设置节点权限 setquota setquota -n|-b val path 设置节点配额 stat stat [-w] path - sync sync path - version - - 第三方客户端-java12345678910111213141516171819202122&lt;!-- zkClient --&gt;&lt;!-- https://mvnrepository.com/artifact/com.101tec/zkclient --&gt;&lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;对应zk版本&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Curator --&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-recipes --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;对应zk版本&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.13&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt;&lt;/dependency&gt;","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://huang-ding.github.io/hexo/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"zk","slug":"zk","permalink":"https://huang-ding.github.io/hexo/tags/zk/"}]},{"title":"分布式系统架构演进之路","slug":"distributed-evolution","date":"2020-05-05T12:11:14.000Z","updated":"2020-05-05T14:45:50.583Z","comments":true,"path":"2020/05/05/distributed-evolution/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/05/05/distributed-evolution/","excerpt":"","text":"演进之路演进之路以一个网站为例 网站一开始就是大型的吗？ 我们应该一开始就设计一个大型网站吗？ 传统企业转型，钱多，召集上百人开发一个大型网站，等开发完结束上线，发现已经成千上百类似的网站，直接夭折。 出生 12graph LRA[无名小网站] --&gt;B[访问量低 一台服务器满足] 当业务发展越来越好，访问用户越来越多，面临问题 性能越来越差 越来越多的数据导致存储空间不足 解决方式 应用服务分离 数据服务分离 123456graph LRA[应用服务器,处理业务逻辑]B[数据库服务器,快速磁盘检索和数据缓存]C[文件服务器,存储用户上传文件]A--&gt;BA--&gt;C 不同的服务器承担不同的服务角色，并发处能利和数据存储空间性能提升 发展了一下 随着用户逐渐增加，网站再次面临挑战 数据库压力太大导致访问延迟，进行影响整个网站的性能，用户体验收到影响 当前用什么技术可以直接了当的解决问题，团队的使用了解情况，最简单的最快速的，技术的选型是有阶段性的，未到阶段不要使用太复杂的解决方案，给团队提高成本 解决方式，使用缓存改善性能 本地缓存 速度极快 数据量有限 和应用程序争抢内存 远程分布式缓存 按需扩展 性能相对本地较差 常用组件 redis memcache 系统架构图 随着用户逐渐增多，单一应用服务器面临新的问题： 能够处理的请求连接有限 网站访问高峰期 应用服务器成为网站瓶颈 解决方案 应用服务器集群，按需扩展 负载均衡调度服务器，需要高性能，高并发 软件 Apache Nginx Reverse-proxy pWEB LVS 硬件 F5 DNS负载均衡，利用域名对应多个IP 扩容（一般不考虑） 发展问题，使用缓存后虽然减轻了数据库压力，但是面临新的问题: 缓存访问不命中 缓存过期 全部的写操作都需要访问数据库 当达到一定规模后，数据库负载压力过大，成为系统瓶颈 解决方式 数据库读写分离 引发问题，数据库访问模块，数据存储层不应该和应用层代码有关系，解决方式 在Mybatis开发插件 mycat Sharding-JDBC 发展问题，用户规模导致地域越来越多，地域网络环境差别很大，面临问题 如何保证用户的访问体验 不至于访问慢流失用户 解决方案 反向代理 缓存静态资源 部署在数据中心，可以和负载均衡是同一个如nginx 地区CDN加速 适用于静态资源 部署在运营商，如电信运营商 加快用户访问速度，减轻后端服务器负载压力 发展问题，单文件服务器，单数据库，面临问题： 存不下日益增长的数据 解决问题： 分布式文件系统（存储小文件，图片） FastDFS TFS 分布式数据库系统(分库分表) Mycat Sharding-JDBC 发展问题，数据的存储需求和检索需求越来越复杂，面临问题 存储的字段差异较大，骷髅表 复杂的文本检索 解决方案： 使用NoSQL MongoDB elasticsearch 搜索引擎 lucene solr elasticsearch 发展问题，网站越来越好，业务越来越大，越来越复杂，面临问题： 应用程序变得无比庞大 迭代周期越来越快 牵一发动全身 怎么应对快速的业务发展需要 解决方案： 业务拆分，按照业务拆分多个为应用程序如，订单，首页，商家，推送 通过链接，MQ，数据存储建立连接 消息队列，RabbitMQ，ActiveMQ，Kafka 发展问题，业务规模不断增大，应用拆分越来越小，越来越多，面临问题 应用间的关系越来越复杂，应用中存在大量相同的业务操作 后端数据库成千上百台应用服务器连接，数据库连接池资源不足 解决方案 分布式服务(服务化) SOA架构 ESB 企业服务总线 中心点瓶颈 服务管理较好，可以在ESB处理 微服务 无中心点 服务框架 Dubbo SoringCloud 引用配置中心 Dubbo - zk SpringCloud config Disconf 百度 Config-toolkit 当当 Diamond 阿里 Apollo 携程 再往后，需要什么？ 数据挖掘 数据分析 推荐等业务需求 庞大的系统监控 问题分析 解决方案 大数据技术 Hadoop Spark 监控 Zabbix ElasticSearch+beats+Kibana 日志分析 ELK集中日志分析系统 以上为当前服务演进过程，当前的service mesh 还未开始琢磨，后续再修改 架构设计思想总结 分而治之 随着网站所需灵活应对 业务发展驱动技术发展，技术发展反哺业务 软件系统的价值在于它能够为用户提供什么价值，在于网站能做什么，而不在于它是怎么做的 不要新技术直接往上堆，考虑当前系统架构和团队技术栈 架构设计误区 一味追随大公司的解决方案 为了技术而技术 新技术可能存在多种系统漏洞 企图用技术解决所有问题 多探讨业务，看是否可以从业务层面解决问题 技术是用来解决业务问题的，而业务的问题，也可以通过业务的手段解决","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://huang-ding.github.io/hexo/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"设计思想","slug":"设计思想","permalink":"https://huang-ding.github.io/hexo/tags/%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/"}]},{"title":"java io 演进","slug":"evolution-io","date":"2020-04-29T13:18:53.000Z","updated":"2020-05-01T09:31:55.064Z","comments":true,"path":"2020/04/29/evolution-io/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/04/29/evolution-io/","excerpt":"","text":"JDK1.0—JDK1.3, java io类库非常原始，很多UNIX网络编程概念或接口在io库都没有体现，如：Buffer，Channel，Selector等 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//最传统单线程处理public class BIOService &#123; public static void main(String[] args) throws IOException &#123; //监听8080端口 ServerSocket socketServer = new ServerSocket(8080); System.out.println(\"启动服务端\"); while (!socketServer.isClosed()) &#123; //阻塞方法 Socket accept = socketServer.accept(); System.out.println(\"收到新链接\" + accept.toString()); try ( //接受数据 net +io InputStream inputStream = accept.getInputStream(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream, StandardCharsets.UTF_8))) &#123; String msg; while ((msg = bufferedReader.readLine()) != null) &#123; if (msg.length() == 0) &#123; break; &#125; System.out.println(msg); &#125; System.out.println(\"收到数据：\" + accept.toString()); &#125; &#125; &#125;&#125;//客户端演示代码public class BIOClient &#123; public static void main(String[] args) &#123; try ( Socket s = new Socket(\"127.0.0.1\", 8080); OutputStream outputStream = s.getOutputStream(); Scanner scanner = new Scanner(System.in)) &#123; System.out.println(\"请输入：\"); String s1 = scanner.nextLine(); //阻塞 写完才返回 outputStream.write(s1.getBytes(StandardCharsets.UTF_8)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//使用多线程技术支持多链接 但是和线程池的大小有关 伪异步IOpublic class BIOService1 &#123; private static ExecutorService threadPool = Executors.newCachedThreadPool(); public static void main(String[] args) throws IOException &#123; //监听8080端口 ServerSocket socketServer = new ServerSocket(8080); System.out.println(\"启动服务端\"); while (!socketServer.isClosed()) &#123; //阻塞方法 Socket accept = socketServer.accept(); System.out.println(\"收到新链接\" + accept.toString()); //线程处理 threadPool.execute(() -&gt; &#123; try &#123; try ( //接受数据 net +io InputStream inputStream = accept.getInputStream(); BufferedReader bufferedReader = new BufferedReader( new InputStreamReader(inputStream, StandardCharsets.UTF_8)); OutputStream outputStream = accept.getOutputStream(); ) &#123; String msg; //读取数据阻塞 while ((msg = bufferedReader.readLine()) != null) &#123; if (msg.length() == 0) &#123; break; &#125; System.out.println(msg); &#125; System.out.println(\"收到数据：\" + accept.toString()); //返回http协议 //写入数据阻塞 outputStream.write(\"HTTP/1.1 200 ok \\r\\n\".getBytes()); outputStream.write(\"Content-Length: 11\\r\\n\\r\\n\".getBytes()); outputStream.write(\"Hello World\".getBytes()); outputStream.flush(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; &#125;&#125;//会引发的问题// 1.如果可用线程都出现故障阻塞，后续所有IO消息都将在队列排队// 2.当队列满后，后续入队操作将被阻塞// 3.新的客户端请求消息将被拒绝，客户端发送大量链接超时// 4.客户认为系统已经崩溃// NIO来解决 JDK1.4 NIO 以JSR-51 的身份正式发布，添加了java.nio包 进行异步IO的缓冲区ByteBuffer 缓存区容量(capacity) 缓冲区位置(position) 缓冲区限制(limit) 堆外缓存及堆内缓存 1234567891011//构建一个堆内内存4字节缓存区ByteBuffer byteBuffer = ByteBuffer.allocate(4);//构建一个堆外内存4字节缓存区,由于不由GC管理，使用是最好先指定JVM的最大堆外缓冲区大小限制；少一次堆拷贝ByteBuffer byteBuffer1 = ByteBuffer.allocateDirect(4);//缓冲区 相关api// flip() 读写反转// compact() 清除已读缓存区// clear() 清除整个缓冲区// rewind() 重置position为0// mark() 标记position的位置// reset() 重置position为上次mark()标记的位置 进行异步IO的管道Pipe 进行各种IO操作的Channel，包括ServerSocketChannel和SocketChannel Channel 通道，提供了NIO的非阻塞方法API，如文件FileChannel，SocketChannel，涵盖了UDP/TCP网络和文件IO，使用缓冲区进行IO操作 12345678910111213141516//SocketChannel和ServiceSocketChannel代码示例//SocketChannel//使用SocketChannel socketChannel = SocketChannel.open();//设置非阻塞模式,默认阻塞模式socketChannel.configureBlocking(false);//链接服务端socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 8080));//ServiceSocketChannel//创建网络服务端ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();//设置非阻塞serverSocketChannel.configureBlocking(false);//绑定端口serverSocketChannel.bind(new InetSocketAddress(8080)); 多种字符集的编码和解码 实现非阻塞IO操作的多路复用选择器Selector Selector选择器，可以通过Channel注册的方式进行检查管道的状态，从而实现单个线程管理多个Channel，从而提高NIO利用效率 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//Selector选择器实现public static void main(String[] args) throws Exception &#123; // 1. 创建网络服务端ServerSocketChannel ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); // 设置为非阻塞模式 // 2. 构建一个Selector选择器,并且将channel注册上去 Selector selector = Selector.open(); SelectionKey selectionKey = serverSocketChannel.register(selector, 0, serverSocketChannel);// 将serverSocketChannel注册到selector selectionKey.interestOps(SelectionKey.OP_ACCEPT); // 对serverSocketChannel上面的accept事件感兴趣(serverSocketChannel只能支持accept操作) // 3. 绑定端口 serverSocketChannel.socket().bind(new InetSocketAddress(8080)); System.out.println(\"启动成功\"); while (true) &#123; // 不再轮询通道,改用下面轮询事件的方式.select方法有阻塞效果,直到有事件通知才会有返回 selector.select(); // 获取事件 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); // 遍历查询结果e Iterator&lt;SelectionKey&gt; iter = selectionKeys.iterator(); while (iter.hasNext()) &#123; // 被封装的查询结果 SelectionKey key = iter.next(); iter.remove(); // 关注 Read 和 Accept两个事件 if (key.isAcceptable()) &#123; ServerSocketChannel server = (ServerSocketChannel) key.attachment(); // 将拿到的客户端连接通道,注册到selector上面 SocketChannel clientSocketChannel = server.accept(); // mainReactor 轮询accept clientSocketChannel.configureBlocking(false); clientSocketChannel.register(selector, SelectionKey.OP_READ, clientSocketChannel); System.out.println(\"收到新连接 : \" + clientSocketChannel.getRemoteAddress()); &#125; if (key.isReadable()) &#123; SocketChannel socketChannel = (SocketChannel) key.attachment(); try &#123; ByteBuffer requestBuffer = ByteBuffer.allocate(1024); while (socketChannel.isOpen() &amp;&amp; socketChannel.read(requestBuffer) != -1) &#123; // 长连接情况下,需要手动判断数据有没有读取结束 (此处做一个简单的判断: 超过0字节就认为请求结束了) if (requestBuffer.position() &gt; 0) break; &#125; if(requestBuffer.position() == 0) continue; // 如果没数据了, 则不继续后面的处理 requestBuffer.flip(); byte[] content = new byte[requestBuffer.limit()]; requestBuffer.get(content); System.out.println(new String(content)); System.out.println(\"收到数据,来自：\" + socketChannel.getRemoteAddress()); // TODO 业务操作 数据库 接口调用等等 // 响应结果 200 String response = \"HTTP/1.1 200 OK\\r\\n\" + \"Content-Length: 11\\r\\n\\r\\n\" + \"Hello World\"; ByteBuffer buffer = ByteBuffer.wrap(response.getBytes()); while (buffer.hasRemaining()) &#123; socketChannel.write(buffer); &#125; &#125; catch (IOException e) &#123; // e.printStackTrace(); key.cancel(); // 取消事件订阅 &#125; &#125; &#125; selector.selectNow(); &#125; // 问题: 此处一个selector监听所有事件,一个线程处理所有请求事件. 会成为瓶颈! 要有多线程的运用 // 使用Reactor线程模型处理问题&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226//单Reactor多线程模式public class ReactorService implements Runnable &#123; private final Selector selector; private final ServerSocketChannel serverSocketChannel; public static void main(String[] args) throws IOException &#123; ReactorService service1 = new ReactorService(8080); service1.run(); &#125; public ReactorService(int port) throws IOException &#123; //创建网络服务端 serverSocketChannel = ServerSocketChannel.open(); //设置非阻塞 serverSocketChannel.configureBlocking(false); //绑定端口 serverSocketChannel.bind(new InetSocketAddress(port)); //创建选择器 selector = Selector.open(); //注册网络服务端，监听链接创建事件 SelectionKey selectionKey = serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); //添加accept 处理事件 selectionKey.attach(new Acceptor()); System.out.println(\"启动完成\"); &#125; @Override public void run() &#123; try &#123; while (!Thread.interrupted()) &#123; //select方法有阻塞效果,直到有事件通知才会有返回 selector.select(); //获取事件 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); for (SelectionKey selectionKey : selectionKeys) &#123; //进行事件派发 dispatch(selectionKey); &#125; selectionKeys.clear(); selector.selectNow(); &#125; &#125; catch (IOException ignored) &#123; &#125; &#125; private void dispatch(SelectionKey selectionKey) &#123; //获取分发事件的附件 /Acceptor/Handler Runnable runnable = (Runnable) selectionKey.attachment(); if (null != runnable) &#123; runnable.run(); &#125; &#125; class Acceptor implements Runnable &#123; /** * 同步获取链接,保证链接获取在同一个Selector */ @Override public synchronized void run() &#123; try &#123; //获取新链接 SocketChannel socketChannel = serverSocketChannel.accept(); if (null != socketChannel) &#123; System.out.println(\"获取到新链接\"); //采用多路复用将事件分发给相应的Handler处理 new Handler(selector, socketChannel); &#125; &#125; catch (IOException i) &#123; &#125; &#125; &#125;&#125;final class Handler implements Runnable &#123; private final SocketChannel socketChannel; private final SelectionKey selectionKey; //处理业务的线程池 private static ExecutorService pool = Executors.newCachedThreadPool(); /** * 创建输入输出缓冲区 */ ByteBuffer input = ByteBuffer.allocate(1024); ByteBuffer output = ByteBuffer.allocate(1024); static final int READING = 0, SENDING = 1, PROCESSING = 3; int state = READING; public Handler(Selector selector, SocketChannel channel) throws IOException &#123; this.socketChannel = channel; //设置非阻塞 socketChannel.configureBlocking(false); //注册事件// SelectionKey.OP_ACCEPT selectionKey = socketChannel.register(selector, 0); //添加附件 selectionKey.attach(this); //表示感兴趣的事件通知 为写 selectionKey.interestOps(SelectionKey.OP_READ); //使Selector.select 返回下一次调用 selector.wakeup(); &#125; /** * 读处理 */ boolean inputIsComplete() throws IOException &#123; int read = socketChannel.read(input); if (read &gt; 0) &#123; input.flip(); byte[] content = new byte[input.limit()]; input.get(content); System.out.println(new String(content)); System.out.println(\"收到数据,来自：\" + socketChannel.getRemoteAddress()); &#125; else if (read &lt; 0) &#123; //对链路进行关闭 返回值-1 说明链路已关闭 selectionKey.cancel(); socketChannel.close(); return false; &#125; else &#123; //读取到0字节 忽略 &#125; return true; &#125; /** * 写处理 */ boolean outputIsComplete() throws IOException &#123; // 响应结果 200 String response = \"HTTP/1.1 200 OK\\r\\n\" + \"Content-Length: 11\\r\\n\\r\\n\" + \"Hello World\"; output.put(response.getBytes()); // hasRemaining 用于判断是否发送完成 防止'写半包'场景 while (output.hasRemaining()) &#123; socketChannel.write(output); &#125; output.clear(); System.out.println(\"写一点东西\"); return true; &#125; /** * 业务处理 */ void process() &#123; System.out.println(\"处理了一些业务\"); &#125; /** * 业务处理 */ void processHandOff() &#123; System.out.println(\"多线程业务处理\"); //修改当前状态 process(); state = SENDING; //表示感兴趣的事件通知 为读 selectionKey.interestOps(SelectionKey.OP_WRITE); &#125; @Override public void run() &#123; try &#123; if (state == READING) &#123; read(); &#125; else if (state == SENDING) &#123; send(); &#125; &#125; catch (IOException e) &#123; &#125; &#125; /** * 读处理 */ void read() throws IOException &#123; socketChannel.read(input); if (inputIsComplete()) &#123; //读完处理业务逻辑 线程池处理业务逻辑 state = PROCESSING; pool.execute(new Processer());// process();// //修改当前状态// state = SENDING;// //表示感兴趣的事件通知 为读// selectionKey.interestOps(SelectionKey.OP_WRITE); &#125; &#125; class Processer implements Runnable &#123; @Override public void run() &#123; processHandOff(); &#125; &#125; /** * 发送到请求方 */ void send() throws IOException &#123; if (outputIsComplete()) &#123; //写完，发送后，删除监听的事件 selectionKey.cancel(); &#125; &#125;&#125; 基于流行的Perl实现的正则表达式 文件通道FileChannel 。。。。。 新的NIO库极大的促进了java异步非阻塞编程的能力，但是还是有不完善的地方，特别是对文件的处理能力不足 没有统一的文件属性（如读写权限） API能力较弱，如目录的级联创建，递归遍历 底层存储系统的一些高级API无法使用 所有文件操作都是同步非阻塞，不支持异步文件读取 2011年JDK1.7发布。将原来的NIO类进行升级，被称为NIO2.0由JSR-203演进而来 提供可以批量获取文件属性的API，提供了标准文件系统SPI，供各个服务提供商扩展 提供AIO功能，支持基于文件的异步IO操作和针对网络套接字Socket的异步操作 完成JSR-51定义的通道功能，包括对配置和多播数据报的支持 提供异步套接字通道实现 通过juc.Future类实现异步操作的结果 在执行异步操作的时候传入CompletionHandler接口的实现类作为操作完成的回调 AIO实现demo 不需要通过多路复用选择器Selector对注册通道进行轮询操作即可实现异步读写，简化了NIO的编程模型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239//服务端public class AIOServer &#123; public static void main(String[] args) &#123; AsyncServerHandler asyncServerHandler = new AsyncServerHandler(8080); new Thread(asyncServerHandler, \"AIO-server\").start(); &#125;&#125;public class AsyncServerHandler implements Runnable &#123; private int port; CountDownLatch latch; AsynchronousServerSocketChannel asynchronousServerSocketChannel; public AsyncServerHandler(int port) &#123; try &#123; //构建异步通道 asynchronousServerSocketChannel = AsynchronousServerSocketChannel.open(); //绑定端口 asynchronousServerSocketChannel.bind(new InetSocketAddress(port)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; latch = new CountDownLatch(1); doAccept(); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private void doAccept() &#123; //接受消息 asynchronousServerSocketChannel.accept(this, new AcceptCompleteHandler()); &#125;&#125;public class AcceptCompleteHandler implements CompletionHandler&lt;AsynchronousSocketChannel, AsyncServerHandler&gt; &#123; @Override public void completed(AsynchronousSocketChannel result, AsyncServerHandler attachment) &#123; //接受客户端链接，因为是异步所以继续调用accept方法，接受其他客户端链接。每当一个客户端链接成功后，再异步接受新的客户端 attachment.asynchronousServerSocketChannel.accept(attachment, this); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); //业务处理 result.read(byteBuffer, byteBuffer, new ReadCompleteHandler(result)); &#125; @Override public void failed(Throwable exc, AsyncServerHandler attachment) &#123; exc.printStackTrace(); attachment.latch.countDown(); &#125;&#125;public class ReadCompleteHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; &#123; private AsynchronousSocketChannel channel; public ReadCompleteHandler(AsynchronousSocketChannel channel) &#123; this.channel = channel; &#125; @Override public void completed(Integer result, ByteBuffer attachment) &#123; attachment.flip(); //获取数据大小 byte[] body = new byte[attachment.remaining()]; //获取数据 attachment.get(body); String req = new String(body, StandardCharsets.UTF_8); System.out.println(\"req：\" + req); //发送数据 doWrite(req); &#125; private void doWrite(String req) &#123; if (null != req &amp;&amp; req.length() &gt; 0) &#123; byte[] bytes = req.getBytes(); //创建缓冲区 ByteBuffer byteBuffer = ByteBuffer.allocate(bytes.length); byteBuffer.put(bytes); byteBuffer.flip(); //异步写入数据 channel.write(byteBuffer, byteBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; //未发送完成继续发送 if (attachment.hasRemaining()) &#123; channel.write(attachment, attachment, this); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; //发生异常关闭连接 try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; //发生异常关闭连接 try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;//客户端public class AIOClient &#123; public static void main(String[] args) &#123; AsyncClientHandler asyncClientHandler = new AsyncClientHandler(\"127.0.0.1\",8080); new Thread(asyncClientHandler,\"AIOClient\").start(); &#125;&#125;public class AsyncClientHandler implements CompletionHandler&lt;Void, AsyncClientHandler&gt;, Runnable &#123; private final String host; private final int port; private AsynchronousSocketChannel channel; private CountDownLatch latch; public AsyncClientHandler(String host, int port) &#123; this.host = host; this.port = port; try &#123; channel = AsynchronousSocketChannel.open(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; latch = new CountDownLatch(1); //建立连接 channel.connect(new InetSocketAddress(host, port), this, this); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; //释放连接 channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void completed(Void result, AsyncClientHandler attachment) &#123; byte[] req = \"Hello world\".getBytes(); ByteBuffer writer = ByteBuffer.allocate(req.length); writer.put(req); writer.flip(); channel.write(writer, writer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; //是否已经写完 if (attachment.hasRemaining()) &#123; //继续写 channel.write(attachment, attachment, this); &#125; else &#123; //写完获取服务端返回数据 ByteBuffer read = ByteBuffer.allocate(1024); channel.read(read, read, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; attachment.flip(); //读取数据 byte[] bytes = new byte[attachment.remaining()]; attachment.get(bytes); String body = new String(bytes, StandardCharsets.UTF_8); System.out.println(body); latch.countDown(); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; latch.countDown(); &#125; &#125;); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; latch.countDown(); &#125; &#125;); &#125; @Override public void failed(Throwable exc, AsyncClientHandler attachment) &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; latch.countDown(); &#125;&#125; 以上NIO演化 ，开始步入netty 开发高质量NIO程序不是一件简单的事情，除去NIO固有的复杂性和BUG，作为NIO服务端，需要处理网络的闪断，客户端重复接入，客户端安全认证，消息的编解码，半包读写等情况，如果没有足够的经验还是使用成熟NIO框架，netty是一个不错的选择","categories":[],"tags":[{"name":"nio","slug":"nio","permalink":"https://huang-ding.github.io/hexo/tags/nio/"}]},{"title":"I/O多路复用","slug":"multiplex-io","date":"2020-04-26T08:29:12.000Z","updated":"2020-04-29T13:14:24.820Z","comments":true,"path":"2020/04/26/multiplex-io/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/04/26/multiplex-io/","excerpt":"","text":"什么是I/O多路复用：通过把多个IO的阻塞复用到一个select的阻塞上，从而让系统在单线程的情况下可以处理多个客户端请求。 场景: 服务器需要同时处理多个处于监听状态或多个连接状态的套接字Socket 服务器需要同时处理多种网络协议的套接字。 目前支持I/O多路复用的系统调用有select，pselect，poll，epool，liunx在新的内核使用epoll，原因如下 支持一个进程打开的Socket描述符（FD）不受限制（仅受操作系统最大句柄数），select默认1024个，查看句柄数（cat /proc/sys/fs/file-max） I/O效率不会随着FD的条目增加而线性下降，epoll只针对‘活跃’的Socket进行操作，‘活跃’会主动调用callback函数 使用mmap加速内核与用户空间的消息传递，epoll通过内核和用户空间mmap同一块内存来实现的 epoll的API更简单","categories":[],"tags":[{"name":"nio","slug":"nio","permalink":"https://huang-ding.github.io/hexo/tags/nio/"}]},{"title":"I/O模型","slug":"nio","date":"2020-04-24T07:47:03.000Z","updated":"2020-04-29T13:14:19.930Z","comments":true,"path":"2020/04/24/nio/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/04/24/nio/","excerpt":"","text":"liunx 网络I/O模型 阻塞I/O模型：一个线程处理一个IO，进程阻塞; 非阻塞I/O模型：缓冲区无数据，返回一个EWOULDBLOCK错误，一般进行轮询检查此状态; I/O复用模型：Liunx提供select/poll,进程通过将文件描述符(fd)传递给select/poll系统调用,阻塞在select操作上，这样select/poll可以侦测多个fd是否处于就绪状态；但是fd数量有限，受到一些制约，因此liunx还提供了一个epoll的系统调用，epool使用基于驱动方式代替顺序扫码，提高性能，当有fd就绪时，立即回调函数rollback; 信号驱动I/O模型：提高开启套接字信号驱动IO功能，并通过系统调用sigaction执行信号处理函数，当数据准备就绪时，就为改进程生成SIGIO信号，通过信号回调通知应用程序调用recvform函数读取数据，并通知主循环函数处理数据 异步I/O模型：告知内核启动某个操作，并让内核在整个操作完成后通知我们。","categories":[{"name":"unix网络模型","slug":"unix网络模型","permalink":"https://huang-ding.github.io/hexo/categories/unix%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"}],"tags":[{"name":"nio","slug":"nio","permalink":"https://huang-ding.github.io/hexo/tags/nio/"},{"name":"网络模型","slug":"网络模型","permalink":"https://huang-ding.github.io/hexo/tags/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"}]}],"categories":[{"name":"unix网络模型","slug":"unix网络模型","permalink":"https://huang-ding.github.io/hexo/categories/unix%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://huang-ding.github.io/hexo/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"zk","slug":"zk","permalink":"https://huang-ding.github.io/hexo/tags/zk/"},{"name":"设计思想","slug":"设计思想","permalink":"https://huang-ding.github.io/hexo/tags/%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/"},{"name":"nio","slug":"nio","permalink":"https://huang-ding.github.io/hexo/tags/nio/"},{"name":"网络模型","slug":"网络模型","permalink":"https://huang-ding.github.io/hexo/tags/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"}]}