{"meta":{"title":"子非鱼","subtitle":"不轻信别人的结论，实践才是检验真理的唯一标准","description":"","author":"haung ding","url":"https://huang-ding.github.io/hexo","root":"/hexo/"},"pages":[{"title":"categories","date":"2020-04-26T07:11:28.000Z","updated":"2020-04-26T07:11:45.866Z","comments":false,"path":"categories/index.html","permalink":"https://huang-ding.github.io/hexo/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-04-26T07:10:24.000Z","updated":"2020-04-26T07:11:17.823Z","comments":false,"path":"tags/index.html","permalink":"https://huang-ding.github.io/hexo/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"zk入门","slug":"distributed-zk","date":"2020-05-06T11:57:23.000Z","updated":"2020-05-06T14:06:57.037Z","comments":true,"path":"2020/05/06/distributed-zk/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/05/06/distributed-zk/","excerpt":"","text":"什么是ZooKeeper起源：ZooKeeper 最早起源于雅虎研究院的一个研究小组。当时，雅虎内部很多大型系统基本都需要依赖一个类似的系统来进行分布式协调，但是这些系统往往都存在分布式单点问题。所以，雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架，以便让开发人员将精力集中在处理业务逻辑上。 简介：Apache Zookeeper是一种用于分布式应用程序的高性能协调服务，提供一种集中式信息存储服务 特点：数据存在内存中，类型文件系统的树形结构（文件和目录），高吞吐和低延迟，集群高可用 作用：基于zookeeper可以实现分布式统一配置中心，服务注册发现，分布式锁等 官网：https://zookeeper.apache.org/ 何为分布式协调服务 单机系统因处理能力上限，可用性，可靠性的考虑，变为分布式系统 原来的单机进程中完成的一件事的多个步骤，变为在多个计算机中完成，这时候就需要协调各个计算机节点做事情的顺序；原来在单系统中资源通过竞争通过锁进行同步控制；现在变成了多个计算机的进程之间的资源竞争，也需要资源协调。 我们可以把每个分布式系统中需要协调的协调管理的公共基础部分抽取出来作为一个基础公共服务，供大家使用，这就是分布式协调 zookeeper的应用案例 Hbase：使用Zookeeper进行Master选举，服务间协调 Solr：使用Zookeeper进行集群管理，Leader选举，配置中心 dubbo：服务注册发现 Mycat：集群管理，配置管理 Sharding-sphere：集群管理，配置管理 。。。。 zookeeper同类产品 consul，etcd，Doozer，等其中etcd和Doozer实现原理，存储方式和zk类似 单机版安装 官网下载对应版本压缩包 3.6.1版本安装包 解压后的conf目录，添加配置文件zoo.cfg（默认文件名，可以不使用此文件名，启动时指定便可） 启动服务端 bin/zkServer.sh start 测试，客户端链接：/bin/zkCli.sh -server 127.0.0.1:2181 123456789//单机版主要配置# The number of milliseconds of each tick 心跳时间tickTime=2000# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes. 数据存放目录dataDir=F:/zk/data# the port at which the clients will connect 客户端链接端口clientPort=2181 客户端操作命令 命令 命令参数 功能描述 addauth addauth scheme auth 创建 &amp;&amp; 验证用户 close - 关闭客户端 config config [-c] [-w] [-s] - connect connect host:port 客户端链接 create create [-s] [-e] [-c] [-t ttl] path [data] [acl] 创建节点 delete delete [-v version] path 删除节点 deleteall deleteall path 删除全部节点 rmr rmr path 递归删除节点 delquota delquota [-n |-b] path 用于删除已经创建的quota配额： get get [-s] [-w] path 获取节点值 getAcl getAcl [-s] path 获取节点信息 getAllChildrenNumber getAllChildrenNumber path 获取所有子节点数 getEphemeral getEphemerals path 获取临时节点 history - - listquota listquota path - ls ls [-s] [-w] [-R] path 获取节点信息 printwatches printwatches on off quit - 退出终端 reconfig [-s] [-v version] [[-file path] [-members serverID=host:port1:port2;port3[,…]*]] - redo redo cmdno - removewatches removewatches path [-c|-d|-a] [-1] - set set [-s] [-v version] path data 设置节点值 setAcl setAcl [-s] [-v version] [-R] path acl 设置节点权限 setquota setquota -n|-b val path 设置节点配额 stat stat [-w] path - sync sync path - version - - 第三方客户端-java1234567891011121314&lt;!-- zkClient --&gt;&lt;!-- https://mvnrepository.com/artifact/com.101tec/zkclient --&gt;&lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;对应zk版本&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Curator --&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-recipes --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;对应zk版本&lt;/version&gt;&lt;/dependency&gt;","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://huang-ding.github.io/hexo/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"zk","slug":"zk","permalink":"https://huang-ding.github.io/hexo/tags/zk/"}]},{"title":"分布式系统架构演进之路","slug":"distributed-evolution","date":"2020-05-05T12:11:14.000Z","updated":"2020-05-05T14:45:50.583Z","comments":true,"path":"2020/05/05/distributed-evolution/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/05/05/distributed-evolution/","excerpt":"","text":"演进之路演进之路以一个网站为例 网站一开始就是大型的吗？ 我们应该一开始就设计一个大型网站吗？ 传统企业转型，钱多，召集上百人开发一个大型网站，等开发完结束上线，发现已经成千上百类似的网站，直接夭折。 出生 12graph LRA[无名小网站] --&gt;B[访问量低 一台服务器满足] 当业务发展越来越好，访问用户越来越多，面临问题 性能越来越差 越来越多的数据导致存储空间不足 解决方式 应用服务分离 数据服务分离 123456graph LRA[应用服务器,处理业务逻辑]B[数据库服务器,快速磁盘检索和数据缓存]C[文件服务器,存储用户上传文件]A--&gt;BA--&gt;C 不同的服务器承担不同的服务角色，并发处能利和数据存储空间性能提升 发展了一下 随着用户逐渐增加，网站再次面临挑战 数据库压力太大导致访问延迟，进行影响整个网站的性能，用户体验收到影响 当前用什么技术可以直接了当的解决问题，团队的使用了解情况，最简单的最快速的，技术的选型是有阶段性的，未到阶段不要使用太复杂的解决方案，给团队提高成本 解决方式，使用缓存改善性能 本地缓存 速度极快 数据量有限 和应用程序争抢内存 远程分布式缓存 按需扩展 性能相对本地较差 常用组件 redis memcache 系统架构图 随着用户逐渐增多，单一应用服务器面临新的问题： 能够处理的请求连接有限 网站访问高峰期 应用服务器成为网站瓶颈 解决方案 应用服务器集群，按需扩展 负载均衡调度服务器，需要高性能，高并发 软件 Apache Nginx Reverse-proxy pWEB LVS 硬件 F5 DNS负载均衡，利用域名对应多个IP 扩容（一般不考虑） 发展问题，使用缓存后虽然减轻了数据库压力，但是面临新的问题: 缓存访问不命中 缓存过期 全部的写操作都需要访问数据库 当达到一定规模后，数据库负载压力过大，成为系统瓶颈 解决方式 数据库读写分离 引发问题，数据库访问模块，数据存储层不应该和应用层代码有关系，解决方式 在Mybatis开发插件 mycat Sharding-JDBC 发展问题，用户规模导致地域越来越多，地域网络环境差别很大，面临问题 如何保证用户的访问体验 不至于访问慢流失用户 解决方案 反向代理 缓存静态资源 部署在数据中心，可以和负载均衡是同一个如nginx 地区CDN加速 适用于静态资源 部署在运营商，如电信运营商 加快用户访问速度，减轻后端服务器负载压力 发展问题，单文件服务器，单数据库，面临问题： 存不下日益增长的数据 解决问题： 分布式文件系统（存储小文件，图片） FastDFS TFS 分布式数据库系统(分库分表) Mycat Sharding-JDBC 发展问题，数据的存储需求和检索需求越来越复杂，面临问题 存储的字段差异较大，骷髅表 复杂的文本检索 解决方案： 使用NoSQL MongoDB elasticsearch 搜索引擎 lucene solr elasticsearch 发展问题，网站越来越好，业务越来越大，越来越复杂，面临问题： 应用程序变得无比庞大 迭代周期越来越快 牵一发动全身 怎么应对快速的业务发展需要 解决方案： 业务拆分，按照业务拆分多个为应用程序如，订单，首页，商家，推送 通过链接，MQ，数据存储建立连接 消息队列，RabbitMQ，ActiveMQ，Kafka 发展问题，业务规模不断增大，应用拆分越来越小，越来越多，面临问题 应用间的关系越来越复杂，应用中存在大量相同的业务操作 后端数据库成千上百台应用服务器连接，数据库连接池资源不足 解决方案 分布式服务(服务化) SOA架构 ESB 企业服务总线 中心点瓶颈 服务管理较好，可以在ESB处理 微服务 无中心点 服务框架 Dubbo SoringCloud 引用配置中心 Dubbo - zk SpringCloud config Disconf 百度 Config-toolkit 当当 Diamond 阿里 Apollo 携程 再往后，需要什么？ 数据挖掘 数据分析 推荐等业务需求 庞大的系统监控 问题分析 解决方案 大数据技术 Hadoop Spark 监控 Zabbix ElasticSearch+beats+Kibana 日志分析 ELK集中日志分析系统 以上为当前服务演进过程，当前的service mesh 还未开始琢磨，后续再修改 架构设计思想总结 分而治之 随着网站所需灵活应对 业务发展驱动技术发展，技术发展反哺业务 软件系统的价值在于它能够为用户提供什么价值，在于网站能做什么，而不在于它是怎么做的 不要新技术直接往上堆，考虑当前系统架构和团队技术栈 架构设计误区 一味追随大公司的解决方案 为了技术而技术 新技术可能存在多种系统漏洞 企图用技术解决所有问题 多探讨业务，看是否可以从业务层面解决问题 技术是用来解决业务问题的，而业务的问题，也可以通过业务的手段解决","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://huang-ding.github.io/hexo/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"设计思想","slug":"设计思想","permalink":"https://huang-ding.github.io/hexo/tags/%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/"}]},{"title":"java io 演进","slug":"evolution-io","date":"2020-04-29T13:18:53.000Z","updated":"2020-05-01T09:31:55.064Z","comments":true,"path":"2020/04/29/evolution-io/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/04/29/evolution-io/","excerpt":"","text":"JDK1.0—JDK1.3, java io类库非常原始，很多UNIX网络编程概念或接口在io库都没有体现，如：Buffer，Channel，Selector等 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//最传统单线程处理public class BIOService &#123; public static void main(String[] args) throws IOException &#123; //监听8080端口 ServerSocket socketServer = new ServerSocket(8080); System.out.println(\"启动服务端\"); while (!socketServer.isClosed()) &#123; //阻塞方法 Socket accept = socketServer.accept(); System.out.println(\"收到新链接\" + accept.toString()); try ( //接受数据 net +io InputStream inputStream = accept.getInputStream(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream, StandardCharsets.UTF_8))) &#123; String msg; while ((msg = bufferedReader.readLine()) != null) &#123; if (msg.length() == 0) &#123; break; &#125; System.out.println(msg); &#125; System.out.println(\"收到数据：\" + accept.toString()); &#125; &#125; &#125;&#125;//客户端演示代码public class BIOClient &#123; public static void main(String[] args) &#123; try ( Socket s = new Socket(\"127.0.0.1\", 8080); OutputStream outputStream = s.getOutputStream(); Scanner scanner = new Scanner(System.in)) &#123; System.out.println(\"请输入：\"); String s1 = scanner.nextLine(); //阻塞 写完才返回 outputStream.write(s1.getBytes(StandardCharsets.UTF_8)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//使用多线程技术支持多链接 但是和线程池的大小有关 伪异步IOpublic class BIOService1 &#123; private static ExecutorService threadPool = Executors.newCachedThreadPool(); public static void main(String[] args) throws IOException &#123; //监听8080端口 ServerSocket socketServer = new ServerSocket(8080); System.out.println(\"启动服务端\"); while (!socketServer.isClosed()) &#123; //阻塞方法 Socket accept = socketServer.accept(); System.out.println(\"收到新链接\" + accept.toString()); //线程处理 threadPool.execute(() -&gt; &#123; try &#123; try ( //接受数据 net +io InputStream inputStream = accept.getInputStream(); BufferedReader bufferedReader = new BufferedReader( new InputStreamReader(inputStream, StandardCharsets.UTF_8)); OutputStream outputStream = accept.getOutputStream(); ) &#123; String msg; //读取数据阻塞 while ((msg = bufferedReader.readLine()) != null) &#123; if (msg.length() == 0) &#123; break; &#125; System.out.println(msg); &#125; System.out.println(\"收到数据：\" + accept.toString()); //返回http协议 //写入数据阻塞 outputStream.write(\"HTTP/1.1 200 ok \\r\\n\".getBytes()); outputStream.write(\"Content-Length: 11\\r\\n\\r\\n\".getBytes()); outputStream.write(\"Hello World\".getBytes()); outputStream.flush(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; &#125;&#125;//会引发的问题// 1.如果可用线程都出现故障阻塞，后续所有IO消息都将在队列排队// 2.当队列满后，后续入队操作将被阻塞// 3.新的客户端请求消息将被拒绝，客户端发送大量链接超时// 4.客户认为系统已经崩溃// NIO来解决 JDK1.4 NIO 以JSR-51 的身份正式发布，添加了java.nio包 进行异步IO的缓冲区ByteBuffer 缓存区容量(capacity) 缓冲区位置(position) 缓冲区限制(limit) 堆外缓存及堆内缓存 1234567891011//构建一个堆内内存4字节缓存区ByteBuffer byteBuffer = ByteBuffer.allocate(4);//构建一个堆外内存4字节缓存区,由于不由GC管理，使用是最好先指定JVM的最大堆外缓冲区大小限制；少一次堆拷贝ByteBuffer byteBuffer1 = ByteBuffer.allocateDirect(4);//缓冲区 相关api// flip() 读写反转// compact() 清除已读缓存区// clear() 清除整个缓冲区// rewind() 重置position为0// mark() 标记position的位置// reset() 重置position为上次mark()标记的位置 进行异步IO的管道Pipe 进行各种IO操作的Channel，包括ServerSocketChannel和SocketChannel Channel 通道，提供了NIO的非阻塞方法API，如文件FileChannel，SocketChannel，涵盖了UDP/TCP网络和文件IO，使用缓冲区进行IO操作 12345678910111213141516//SocketChannel和ServiceSocketChannel代码示例//SocketChannel//使用SocketChannel socketChannel = SocketChannel.open();//设置非阻塞模式,默认阻塞模式socketChannel.configureBlocking(false);//链接服务端socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 8080));//ServiceSocketChannel//创建网络服务端ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();//设置非阻塞serverSocketChannel.configureBlocking(false);//绑定端口serverSocketChannel.bind(new InetSocketAddress(8080)); 多种字符集的编码和解码 实现非阻塞IO操作的多路复用选择器Selector Selector选择器，可以通过Channel注册的方式进行检查管道的状态，从而实现单个线程管理多个Channel，从而提高NIO利用效率 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//Selector选择器实现public static void main(String[] args) throws Exception &#123; // 1. 创建网络服务端ServerSocketChannel ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); // 设置为非阻塞模式 // 2. 构建一个Selector选择器,并且将channel注册上去 Selector selector = Selector.open(); SelectionKey selectionKey = serverSocketChannel.register(selector, 0, serverSocketChannel);// 将serverSocketChannel注册到selector selectionKey.interestOps(SelectionKey.OP_ACCEPT); // 对serverSocketChannel上面的accept事件感兴趣(serverSocketChannel只能支持accept操作) // 3. 绑定端口 serverSocketChannel.socket().bind(new InetSocketAddress(8080)); System.out.println(\"启动成功\"); while (true) &#123; // 不再轮询通道,改用下面轮询事件的方式.select方法有阻塞效果,直到有事件通知才会有返回 selector.select(); // 获取事件 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); // 遍历查询结果e Iterator&lt;SelectionKey&gt; iter = selectionKeys.iterator(); while (iter.hasNext()) &#123; // 被封装的查询结果 SelectionKey key = iter.next(); iter.remove(); // 关注 Read 和 Accept两个事件 if (key.isAcceptable()) &#123; ServerSocketChannel server = (ServerSocketChannel) key.attachment(); // 将拿到的客户端连接通道,注册到selector上面 SocketChannel clientSocketChannel = server.accept(); // mainReactor 轮询accept clientSocketChannel.configureBlocking(false); clientSocketChannel.register(selector, SelectionKey.OP_READ, clientSocketChannel); System.out.println(\"收到新连接 : \" + clientSocketChannel.getRemoteAddress()); &#125; if (key.isReadable()) &#123; SocketChannel socketChannel = (SocketChannel) key.attachment(); try &#123; ByteBuffer requestBuffer = ByteBuffer.allocate(1024); while (socketChannel.isOpen() &amp;&amp; socketChannel.read(requestBuffer) != -1) &#123; // 长连接情况下,需要手动判断数据有没有读取结束 (此处做一个简单的判断: 超过0字节就认为请求结束了) if (requestBuffer.position() &gt; 0) break; &#125; if(requestBuffer.position() == 0) continue; // 如果没数据了, 则不继续后面的处理 requestBuffer.flip(); byte[] content = new byte[requestBuffer.limit()]; requestBuffer.get(content); System.out.println(new String(content)); System.out.println(\"收到数据,来自：\" + socketChannel.getRemoteAddress()); // TODO 业务操作 数据库 接口调用等等 // 响应结果 200 String response = \"HTTP/1.1 200 OK\\r\\n\" + \"Content-Length: 11\\r\\n\\r\\n\" + \"Hello World\"; ByteBuffer buffer = ByteBuffer.wrap(response.getBytes()); while (buffer.hasRemaining()) &#123; socketChannel.write(buffer); &#125; &#125; catch (IOException e) &#123; // e.printStackTrace(); key.cancel(); // 取消事件订阅 &#125; &#125; &#125; selector.selectNow(); &#125; // 问题: 此处一个selector监听所有事件,一个线程处理所有请求事件. 会成为瓶颈! 要有多线程的运用 // 使用Reactor线程模型处理问题&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226//单Reactor多线程模式public class ReactorService implements Runnable &#123; private final Selector selector; private final ServerSocketChannel serverSocketChannel; public static void main(String[] args) throws IOException &#123; ReactorService service1 = new ReactorService(8080); service1.run(); &#125; public ReactorService(int port) throws IOException &#123; //创建网络服务端 serverSocketChannel = ServerSocketChannel.open(); //设置非阻塞 serverSocketChannel.configureBlocking(false); //绑定端口 serverSocketChannel.bind(new InetSocketAddress(port)); //创建选择器 selector = Selector.open(); //注册网络服务端，监听链接创建事件 SelectionKey selectionKey = serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); //添加accept 处理事件 selectionKey.attach(new Acceptor()); System.out.println(\"启动完成\"); &#125; @Override public void run() &#123; try &#123; while (!Thread.interrupted()) &#123; //select方法有阻塞效果,直到有事件通知才会有返回 selector.select(); //获取事件 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); for (SelectionKey selectionKey : selectionKeys) &#123; //进行事件派发 dispatch(selectionKey); &#125; selectionKeys.clear(); selector.selectNow(); &#125; &#125; catch (IOException ignored) &#123; &#125; &#125; private void dispatch(SelectionKey selectionKey) &#123; //获取分发事件的附件 /Acceptor/Handler Runnable runnable = (Runnable) selectionKey.attachment(); if (null != runnable) &#123; runnable.run(); &#125; &#125; class Acceptor implements Runnable &#123; /** * 同步获取链接,保证链接获取在同一个Selector */ @Override public synchronized void run() &#123; try &#123; //获取新链接 SocketChannel socketChannel = serverSocketChannel.accept(); if (null != socketChannel) &#123; System.out.println(\"获取到新链接\"); //采用多路复用将事件分发给相应的Handler处理 new Handler(selector, socketChannel); &#125; &#125; catch (IOException i) &#123; &#125; &#125; &#125;&#125;final class Handler implements Runnable &#123; private final SocketChannel socketChannel; private final SelectionKey selectionKey; //处理业务的线程池 private static ExecutorService pool = Executors.newCachedThreadPool(); /** * 创建输入输出缓冲区 */ ByteBuffer input = ByteBuffer.allocate(1024); ByteBuffer output = ByteBuffer.allocate(1024); static final int READING = 0, SENDING = 1, PROCESSING = 3; int state = READING; public Handler(Selector selector, SocketChannel channel) throws IOException &#123; this.socketChannel = channel; //设置非阻塞 socketChannel.configureBlocking(false); //注册事件// SelectionKey.OP_ACCEPT selectionKey = socketChannel.register(selector, 0); //添加附件 selectionKey.attach(this); //表示感兴趣的事件通知 为写 selectionKey.interestOps(SelectionKey.OP_READ); //使Selector.select 返回下一次调用 selector.wakeup(); &#125; /** * 读处理 */ boolean inputIsComplete() throws IOException &#123; int read = socketChannel.read(input); if (read &gt; 0) &#123; input.flip(); byte[] content = new byte[input.limit()]; input.get(content); System.out.println(new String(content)); System.out.println(\"收到数据,来自：\" + socketChannel.getRemoteAddress()); &#125; else if (read &lt; 0) &#123; //对链路进行关闭 返回值-1 说明链路已关闭 selectionKey.cancel(); socketChannel.close(); return false; &#125; else &#123; //读取到0字节 忽略 &#125; return true; &#125; /** * 写处理 */ boolean outputIsComplete() throws IOException &#123; // 响应结果 200 String response = \"HTTP/1.1 200 OK\\r\\n\" + \"Content-Length: 11\\r\\n\\r\\n\" + \"Hello World\"; output.put(response.getBytes()); // hasRemaining 用于判断是否发送完成 防止'写半包'场景 while (output.hasRemaining()) &#123; socketChannel.write(output); &#125; output.clear(); System.out.println(\"写一点东西\"); return true; &#125; /** * 业务处理 */ void process() &#123; System.out.println(\"处理了一些业务\"); &#125; /** * 业务处理 */ void processHandOff() &#123; System.out.println(\"多线程业务处理\"); //修改当前状态 process(); state = SENDING; //表示感兴趣的事件通知 为读 selectionKey.interestOps(SelectionKey.OP_WRITE); &#125; @Override public void run() &#123; try &#123; if (state == READING) &#123; read(); &#125; else if (state == SENDING) &#123; send(); &#125; &#125; catch (IOException e) &#123; &#125; &#125; /** * 读处理 */ void read() throws IOException &#123; socketChannel.read(input); if (inputIsComplete()) &#123; //读完处理业务逻辑 线程池处理业务逻辑 state = PROCESSING; pool.execute(new Processer());// process();// //修改当前状态// state = SENDING;// //表示感兴趣的事件通知 为读// selectionKey.interestOps(SelectionKey.OP_WRITE); &#125; &#125; class Processer implements Runnable &#123; @Override public void run() &#123; processHandOff(); &#125; &#125; /** * 发送到请求方 */ void send() throws IOException &#123; if (outputIsComplete()) &#123; //写完，发送后，删除监听的事件 selectionKey.cancel(); &#125; &#125;&#125; 基于流行的Perl实现的正则表达式 文件通道FileChannel 。。。。。 新的NIO库极大的促进了java异步非阻塞编程的能力，但是还是有不完善的地方，特别是对文件的处理能力不足 没有统一的文件属性（如读写权限） API能力较弱，如目录的级联创建，递归遍历 底层存储系统的一些高级API无法使用 所有文件操作都是同步非阻塞，不支持异步文件读取 2011年JDK1.7发布。将原来的NIO类进行升级，被称为NIO2.0由JSR-203演进而来 提供可以批量获取文件属性的API，提供了标准文件系统SPI，供各个服务提供商扩展 提供AIO功能，支持基于文件的异步IO操作和针对网络套接字Socket的异步操作 完成JSR-51定义的通道功能，包括对配置和多播数据报的支持 提供异步套接字通道实现 通过juc.Future类实现异步操作的结果 在执行异步操作的时候传入CompletionHandler接口的实现类作为操作完成的回调 AIO实现demo 不需要通过多路复用选择器Selector对注册通道进行轮询操作即可实现异步读写，简化了NIO的编程模型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239//服务端public class AIOServer &#123; public static void main(String[] args) &#123; AsyncServerHandler asyncServerHandler = new AsyncServerHandler(8080); new Thread(asyncServerHandler, \"AIO-server\").start(); &#125;&#125;public class AsyncServerHandler implements Runnable &#123; private int port; CountDownLatch latch; AsynchronousServerSocketChannel asynchronousServerSocketChannel; public AsyncServerHandler(int port) &#123; try &#123; //构建异步通道 asynchronousServerSocketChannel = AsynchronousServerSocketChannel.open(); //绑定端口 asynchronousServerSocketChannel.bind(new InetSocketAddress(port)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; latch = new CountDownLatch(1); doAccept(); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private void doAccept() &#123; //接受消息 asynchronousServerSocketChannel.accept(this, new AcceptCompleteHandler()); &#125;&#125;public class AcceptCompleteHandler implements CompletionHandler&lt;AsynchronousSocketChannel, AsyncServerHandler&gt; &#123; @Override public void completed(AsynchronousSocketChannel result, AsyncServerHandler attachment) &#123; //接受客户端链接，因为是异步所以继续调用accept方法，接受其他客户端链接。每当一个客户端链接成功后，再异步接受新的客户端 attachment.asynchronousServerSocketChannel.accept(attachment, this); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); //业务处理 result.read(byteBuffer, byteBuffer, new ReadCompleteHandler(result)); &#125; @Override public void failed(Throwable exc, AsyncServerHandler attachment) &#123; exc.printStackTrace(); attachment.latch.countDown(); &#125;&#125;public class ReadCompleteHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; &#123; private AsynchronousSocketChannel channel; public ReadCompleteHandler(AsynchronousSocketChannel channel) &#123; this.channel = channel; &#125; @Override public void completed(Integer result, ByteBuffer attachment) &#123; attachment.flip(); //获取数据大小 byte[] body = new byte[attachment.remaining()]; //获取数据 attachment.get(body); String req = new String(body, StandardCharsets.UTF_8); System.out.println(\"req：\" + req); //发送数据 doWrite(req); &#125; private void doWrite(String req) &#123; if (null != req &amp;&amp; req.length() &gt; 0) &#123; byte[] bytes = req.getBytes(); //创建缓冲区 ByteBuffer byteBuffer = ByteBuffer.allocate(bytes.length); byteBuffer.put(bytes); byteBuffer.flip(); //异步写入数据 channel.write(byteBuffer, byteBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; //未发送完成继续发送 if (attachment.hasRemaining()) &#123; channel.write(attachment, attachment, this); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; //发生异常关闭连接 try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; //发生异常关闭连接 try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;//客户端public class AIOClient &#123; public static void main(String[] args) &#123; AsyncClientHandler asyncClientHandler = new AsyncClientHandler(\"127.0.0.1\",8080); new Thread(asyncClientHandler,\"AIOClient\").start(); &#125;&#125;public class AsyncClientHandler implements CompletionHandler&lt;Void, AsyncClientHandler&gt;, Runnable &#123; private final String host; private final int port; private AsynchronousSocketChannel channel; private CountDownLatch latch; public AsyncClientHandler(String host, int port) &#123; this.host = host; this.port = port; try &#123; channel = AsynchronousSocketChannel.open(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; latch = new CountDownLatch(1); //建立连接 channel.connect(new InetSocketAddress(host, port), this, this); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; //释放连接 channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void completed(Void result, AsyncClientHandler attachment) &#123; byte[] req = \"Hello world\".getBytes(); ByteBuffer writer = ByteBuffer.allocate(req.length); writer.put(req); writer.flip(); channel.write(writer, writer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; //是否已经写完 if (attachment.hasRemaining()) &#123; //继续写 channel.write(attachment, attachment, this); &#125; else &#123; //写完获取服务端返回数据 ByteBuffer read = ByteBuffer.allocate(1024); channel.read(read, read, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; attachment.flip(); //读取数据 byte[] bytes = new byte[attachment.remaining()]; attachment.get(bytes); String body = new String(bytes, StandardCharsets.UTF_8); System.out.println(body); latch.countDown(); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; latch.countDown(); &#125; &#125;); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; latch.countDown(); &#125; &#125;); &#125; @Override public void failed(Throwable exc, AsyncClientHandler attachment) &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; latch.countDown(); &#125;&#125; 以上NIO演化 ，开始步入netty 开发高质量NIO程序不是一件简单的事情，除去NIO固有的复杂性和BUG，作为NIO服务端，需要处理网络的闪断，客户端重复接入，客户端安全认证，消息的编解码，半包读写等情况，如果没有足够的经验还是使用成熟NIO框架，netty是一个不错的选择","categories":[],"tags":[{"name":"nio","slug":"nio","permalink":"https://huang-ding.github.io/hexo/tags/nio/"}]},{"title":"I/O多路复用","slug":"multiplex-io","date":"2020-04-26T08:29:12.000Z","updated":"2020-04-29T13:14:24.820Z","comments":true,"path":"2020/04/26/multiplex-io/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/04/26/multiplex-io/","excerpt":"","text":"什么是I/O多路复用：通过把多个IO的阻塞复用到一个select的阻塞上，从而让系统在单线程的情况下可以处理多个客户端请求。 场景: 服务器需要同时处理多个处于监听状态或多个连接状态的套接字Socket 服务器需要同时处理多种网络协议的套接字。 目前支持I/O多路复用的系统调用有select，pselect，poll，epool，liunx在新的内核使用epoll，原因如下 支持一个进程打开的Socket描述符（FD）不受限制（仅受操作系统最大句柄数），select默认1024个，查看句柄数（cat /proc/sys/fs/file-max） I/O效率不会随着FD的条目增加而线性下降，epoll只针对‘活跃’的Socket进行操作，‘活跃’会主动调用callback函数 使用mmap加速内核与用户空间的消息传递，epoll通过内核和用户空间mmap同一块内存来实现的 epoll的API更简单","categories":[],"tags":[{"name":"nio","slug":"nio","permalink":"https://huang-ding.github.io/hexo/tags/nio/"}]},{"title":"I/O模型","slug":"nio","date":"2020-04-24T07:47:03.000Z","updated":"2020-04-29T13:14:19.930Z","comments":true,"path":"2020/04/24/nio/","link":"","permalink":"https://huang-ding.github.io/hexo/2020/04/24/nio/","excerpt":"","text":"liunx 网络I/O模型 阻塞I/O模型：一个线程处理一个IO，进程阻塞; 非阻塞I/O模型：缓冲区无数据，返回一个EWOULDBLOCK错误，一般进行轮询检查此状态; I/O复用模型：Liunx提供select/poll,进程通过将文件描述符(fd)传递给select/poll系统调用,阻塞在select操作上，这样select/poll可以侦测多个fd是否处于就绪状态；但是fd数量有限，受到一些制约，因此liunx还提供了一个epoll的系统调用，epool使用基于驱动方式代替顺序扫码，提高性能，当有fd就绪时，立即回调函数rollback; 信号驱动I/O模型：提高开启套接字信号驱动IO功能，并通过系统调用sigaction执行信号处理函数，当数据准备就绪时，就为改进程生成SIGIO信号，通过信号回调通知应用程序调用recvform函数读取数据，并通知主循环函数处理数据 异步I/O模型：告知内核启动某个操作，并让内核在整个操作完成后通知我们。","categories":[{"name":"unix网络模型","slug":"unix网络模型","permalink":"https://huang-ding.github.io/hexo/categories/unix%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"}],"tags":[{"name":"nio","slug":"nio","permalink":"https://huang-ding.github.io/hexo/tags/nio/"},{"name":"网络模型","slug":"网络模型","permalink":"https://huang-ding.github.io/hexo/tags/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"}]}],"categories":[{"name":"unix网络模型","slug":"unix网络模型","permalink":"https://huang-ding.github.io/hexo/categories/unix%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://huang-ding.github.io/hexo/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"zk","slug":"zk","permalink":"https://huang-ding.github.io/hexo/tags/zk/"},{"name":"设计思想","slug":"设计思想","permalink":"https://huang-ding.github.io/hexo/tags/%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/"},{"name":"nio","slug":"nio","permalink":"https://huang-ding.github.io/hexo/tags/nio/"},{"name":"网络模型","slug":"网络模型","permalink":"https://huang-ding.github.io/hexo/tags/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"}]}